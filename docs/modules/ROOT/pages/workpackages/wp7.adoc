= WP7: Showroom, Benchmarking, and Co-Design Coordination
:page-tags: manual,wp
:parent-catalogs: wp-catalog
:page-illustration: fa-solid fa-display
:icons: font

[.lead]
WP7 integrates, tests, and benchmarks methods and software from all WPs, coordinates co-design activities with ExaDIP, and delivers the showroom, CI/CD infrastructure, and training materials.

[discrete]
== Recent Highlights (2024-2025)

[.grid.grid-3.gap-2]
====
____
icon:sync-alt[size=2x,role=text-success] *CI/CD Automation*

CI/CD pipelines validating new methods and software deliveries
____

____
icon:rocket[size=2x,role=text-primary] *24h Turnaround*

Automated code → EuroHPC runs in < 24h
____

____
icon:th[size=2x,role=text-info] *Showroom Updated*

Showroom content updated with meshing, solver, and ML workflows
____

____
icon:box[size=2x,role=text-warning] *Containers Published*

Containers and packages published (Spack, Guix, Docker, Apptainer)
____

____
icon:graduation-cap[size=2x,role=text-danger] *Training Available*

Training modules on CI/CD and benchmarking best practices
____
====

== Objectives

WP7 provides the infrastructure and coordination for:

* Software testing from simple to advanced benchmarking
* Verification of exascale capabilities and handling of identified challenges (B1-B13)
* Delivery of software packages with CI/CD framework
* Coordination of co-design activities within Exa-MA and with ExaDIP
* Showroom of Exa-MA results and training material

== Integration Framework

[.section-gray]
--
[mermaid]
....
graph TB
    A[WP1-WP6 Deliverables] --> B[Non-Regression Tests]
    A --> C[Verification Tests]
    A --> D[Validation Tests]

    B --> E[Testing Environment]
    C --> E
    D --> E

    E --> F[Level 1 Demonstrators]
    E --> G[Level 2 Demonstrators]
    E --> H[Level 3 Demonstrators]

    F --> I[CI/CD Pipeline]
    G --> I
    H --> I

    I --> J[EuroHPC Systems]

    J --> K[Performance Metrics]
    J --> L[Showroom Pages]
    J --> M[Training Material]

    style A fill:#e1f5ff
    style E fill:#ffe1f5
    style F fill:#fff4e1
    style G fill:#f5ffe1
    style H fill:#e1e1ff
    style I fill:#e1ffe1
    style J fill:#ffe1e1
....
--

== Key Tasks

[discrete]
=== T7.1: Testing and Benchmarking Environment
* Identify each relevant demonstrator to define a validation laboratory
* Three types of demonstrators:
  - **Level 1**: Covers one to two WPs (e.g., AMR techniques)
  - **Level 2**: Covers three to four WPs
  - **Level 3**: Potentially covers all WPs
* Some demonstrators retained by PC5 benefit from "mini apps" development and support

[discrete]
=== T7.2: Co-design Activities Coordination
* Integration process based on all demonstrators
* Broken down into non-regression, verification and validation processes
* Each demonstrator must deliver current test process to guarantee integrity
* Guarantee non-regression while evaluating new features
* Record cases as new non-regression, verification or validation tests
* Add new tests based solely on functionality tested
* Enrich original base if necessary to better evaluate contribution of new methods

[discrete]
=== T7.3: Showroom Coordination
* Describe obtained results in unique format
* Present in dedicated web page
* Compare results with initial objectives in terms of performance
* Illustrate with figure of merit and raw data (clock time, resources used, computer)
* Systematically compare with initial performance of the demonstrator

[discrete]
=== T7.4: Training
* Produce training material on exascale toolboxes and mini-apps
* Document best practices for exascale computing
* Create reproducible examples and tutorials

== Leads & Partners

[cols="2,3"]
|===
|Lead Institution |CEA (initially UNISTRA)
|Co-Leaders |UNISTRA, Inria, École Polytechnique, Sorbonne Université
|Duration |Months 1-60+
|===

== Addressed Exascale Bottlenecks

WP7 addresses **ALL bottlenecks (B1-B13)** through:

* Benchmarking to verify exascale capabilities
* Handling of all identified challenges
* Non-regression, verification and validation testing
* CI/CD integration with ExaDIP

*Bottlenecks: B1 (Energy efficiency), B2 (Interconnect), B3 (Memory), B4 (System software), B5 (Programming systems), B6 (Data Management), B7 (Exascale Algorithms), B8 (Discovery/design/decision), B9 (Resilience/robustness/accuracy), B10 (Scientific productivity), B11 (Reproducibility/replicability), B12 (Pre/Post processing), B13 (Integrate uncertainties)*

== Deliverables

[cols="1,3,1"]
|===
|ID |Title |Due Dates

|D7.1-B
|Benchmarking analysis report (bottlenecks and breakthroughs)
|M12, M24, M36, M48, M60

|D7.2-MR
|Co-design report
|M48, M60

|D7.3-TR
|Training material
|M12, M24, M36, M48, M60

|D7.4-MR
|Activity reports (included in annual report D0.2-TR)
|M12, M24, M36, M48, M60
|===

== Collaborations

* **All WPs (WP1-WP6)**: Benchmarking and testing of all developments
* **WP0**: Follows project management plan
* **NumPEx Projects**: ExaSoft, ExaDoST, ExaAToW, ExaDIP (CI/CD and co-design)
